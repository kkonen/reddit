{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generic query function for the pushshift.io Reddit API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query_reddit(subreddit = '', type = 'comment', username = '',\n",
    "                 before = '', link_id='', size = 1000):\n",
    "\n",
    "    params = {}\n",
    "    fields = ['subreddit', 'created_utc', 'body', 'author',\n",
    "                     'title', 'selftext',\n",
    "                     'link_id', 'id', 'permalink']\n",
    "\n",
    "    #params['fields'] = fields\n",
    "    params['size'] = size\n",
    "\n",
    "    if before:\n",
    "        params['before'] = before\n",
    "    if username:\n",
    "        params['author'] = username\n",
    "    if subreddit:\n",
    "        params['subreddit'] = subreddit\n",
    "    if link_id:\n",
    "        params['link_id'] = link_id\n",
    "    response = requests.get(\n",
    "        'https://api.pushshift.io/reddit/' + type + '/search',\n",
    "        params=params\n",
    "    )\n",
    "    try:\n",
    "        if 'data' in response.json():\n",
    "            return response.json()['data']\n",
    "        else:\n",
    "            return {}\n",
    "    except:\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# begin = ''\n",
    "# while True:\n",
    "#     doc = query_reddit('submission', 'AutoModerator', before = begin)\n",
    "#     length = len(doc)\n",
    "#     begin = doc[length - 1]['created_utc']  if length > 0 else ''\n",
    "#     print(length)\n",
    "#     print(begin)\n",
    "#     print('_________')\n",
    "#     if not begin:\n",
    "#         break\n",
    "\n",
    "# doc = query_reddit(type = 'submission', username = 'AutoModerator')\n",
    "# length = len(doc)\n",
    "# begin = doc[length - 1]['created_utc']  if length > 0 else ''\n",
    "# print(length)\n",
    "# print(begin)\n",
    "# print('_________')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Functions to poll submissions and comments\n",
    "\n",
    "# get_submissions:\n",
    "id: ID of the submission. this is called link_id in comments!!\n",
    "# get_comments:\n",
    "link_id: ID of the submission where the comment was made!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "all_submissions = []\n",
    "all_comments = []\n",
    "\n",
    "def get_submissions(subreddit):\n",
    "    loading_text = \"~\"\n",
    "    begin = ''\n",
    "    while True:\n",
    "#     for _ in itertools.repeat(None, 1):\n",
    "        doc =  query_reddit(subreddit=subreddit, type='submission', before=begin)\n",
    "        length = len(doc)\n",
    "        begin = doc[length - 1]['created_utc']  if length > 0 else ''\n",
    "        if not begin:\n",
    "            break\n",
    "        for submission in doc: \n",
    "            all_submissions.append(submission)\n",
    "        clear_output(wait=True)\n",
    "        display(loading_text)\n",
    "        if len(loading_text) < 10:\n",
    "            loading_text = '~' + loading_text\n",
    "        else:\n",
    "            loading_text = '~'\n",
    "    with open('submissions_authors_news.csv', 'w') as f:\n",
    "        for item in all_submissions:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        f.close()\n",
    "    print(\"Ding!\")\n",
    "\n",
    "\n",
    "def get_comments(subreddit):\n",
    "    loading_text = \"~\"\n",
    "    begin = ''\n",
    "    while True:\n",
    "#     for _ in itertools.repeat(None, 10):\n",
    "        doc =  query_reddit(subreddit=subreddit, type='comment', before=begin)\n",
    "        length = len(doc)\n",
    "        begin = doc[length - 1]['created_utc']  if length > 0 else ''\n",
    "        if not begin:\n",
    "            break\n",
    "        for comments in doc:\n",
    "            all_comments.append(comments)\n",
    "        clear_output(wait=True)\n",
    "        display(loading_text)\n",
    "        if len(loading_text) < 10:\n",
    "            loading_text = '~' + loading_text\n",
    "        else:\n",
    "            loading_text = '~'\n",
    "\n",
    "    with open('comments_star_wars.csv', 'w') as f:\n",
    "        for item in all_comments:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        f.close()\n",
    "    print(\"Ding!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get all comments of all submissions (crashes randomly?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comments_under_submissions = []\n",
    "def comments_from_submissions():\n",
    "\n",
    "    f = open('comments_of_submissions_news.csv', 'w')\n",
    "    for submission in all_submissions:\n",
    "        begin = ''\n",
    "        entry = {}\n",
    "        entry['link_id'] = submission['id']\n",
    "        entry['comments'] = []\n",
    "        if 'id' in submission:\n",
    "            while True:\n",
    "                doc =  query_reddit(subreddit='news', type='comment',\n",
    "                                    link_id = submission['id'], before = begin)\n",
    "                if doc:\n",
    "                    begin = doc[-1]['created_utc']\n",
    "                else:\n",
    "                    break\n",
    "                for comment in doc:\n",
    "                    entry['comments'].append(comment)\n",
    "        f.write(\"%s\\n\" % entry)\n",
    "        print(entry['comments'])\n",
    "    f.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~~~~~~~'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding!\n"
     ]
    }
   ],
   "source": [
    "# get_submissions()\n",
    "get_comments()\n",
    "# comments_from_submissions()\n",
    "# print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
